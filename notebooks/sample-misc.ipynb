{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample-misc\n",
    "\n",
    "A sample notebook for miscellaneous code and experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda deactivate && conda env update --file glider-utils/environment.yml --prune\n",
    "# from subprocess import run\n",
    "# run([\"/home/sam_woodman_noaa_gov/glider-utils/resources/sync-cache.sh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyglider import slocum\n",
    "from pyglider import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from esdglider.pathutils import get_engyml_path\n",
    "from esdglider.utils import postproc_eng_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacdir = \"../resources/example-data/cache\"\n",
    "binarydir = \"../resources/example-data/binary-delayed\"\n",
    "deploymentyaml = \"../resources/example-data/amlr08-20220513-delayed.yml\"\n",
    "engyaml = get_engyml_path()\n",
    "outdir = \"../resources/example-data/out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1ts_outname_sci = slocum.binary_to_timeseries(\n",
    "    binarydir, cacdir, outdir, deploymentyaml,\n",
    "    search='*.[D|E|d|e]bd', fnamesuffix='-sci',\n",
    "    time_base='sci_water_temp', profile_filt_time=100,\n",
    "    profile_min_time=300, maxgap=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1ts_outname_eng = slocum.binary_to_timeseries(\n",
    "    binarydir, cacdir, outdir, \n",
    "    [deploymentyaml, engyaml],\n",
    "    search='*.[D|E|d|e]bd', fnamesuffix='-eng',\n",
    "    # search='*.[D|E]BD', fnamesuffix='',\n",
    "    time_base='m_depth', profile_filt_time=100,\n",
    "    profile_min_time=300, maxgap=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_sci = xr.open_dataset(l1ts_outname_sci)\n",
    "# ts_oxy = xr.open_dataset(os.path.join(l1tsdir, f\"{deployment}-oxy.nc\"))\n",
    "ts_sci\n",
    "# list(ts_sci.data_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_eng = xr.open_dataset(l1ts_outname_eng)\n",
    "ts_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postproc_eng_timeseries(ts_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_eng.attrs[\"comment\"]\n",
    "print(not ts_eng.attrs[\"comment\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_sci.close()\n",
    "# ts_oxy.close()\n",
    "# ts_eng.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dbdreader exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dbdreader\n",
    "dbd = dbdreader.MultiDBD(pattern=f'{binarydir}/{'*.[D|E|d|e]bd'}',\n",
    "                        cacheDir=cacdir)\n",
    "# x=[v for _,v in dbd.get(*param_names, return_nans=True)]\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"m_depth\", \"m_heading\", \"m_pitch\", \"m_roll\", \"m_tot_num_inflections\"]\n",
    "t1, d = dbd.get(param_names[0], return_nans=True)\n",
    "t2, h = dbd.get(param_names[1], return_nans=True)\n",
    "t3, p = dbd.get(param_names[2], return_nans=True)\n",
    "t4, r = dbd.get(param_names[3], return_nans=True)\n",
    "t5, i = dbd.get(param_names[4], return_nans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where array1 is NaN\n",
    "nan_in_array1 = np.isnan(d)\n",
    "\n",
    "# Check if values in arrays 2-4 are NOT NaN at positions where array1 is NaN\n",
    "non_nan_in_arrays_2_to_4 = (~np.isnan(h) | ~np.isnan(p) | ~np.isnan(r)) & nan_in_array1\n",
    "\n",
    "# Indices where array1 is NaN and any of arrays 2-4 is not NaN\n",
    "indices = np.where(non_nan_in_arrays_2_to_4)[0]\n",
    "\n",
    "# Output the indices\n",
    "print(\"Indices where array1 is NaN and arrays 2-4 are not NaN:\", indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing times\n",
    "\n",
    "Main purpose of this section is to confirm that xarray.merge is doing what we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = ts_sci.time.to_numpy()\n",
    "# t2 = ts_oxy.time.to_numpy()\n",
    "t3 = ts_eng.time.to_numpy()\n",
    "\n",
    "df_union = np.union1d(t1, t3)\n",
    "print(len(t1))\n",
    "print(len(t3))\n",
    "print(len(df_union))\n",
    "df_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_all = ['latitude', 'longitude', 'waypoint_latitude', 'waypoint_longitude']\n",
    "sci_vars = vars_all + ['conductivity', 'temperature', 'pressure',\n",
    "            'depth', 'salinity', 'potential_density', 'density', 'potential_temperature',\n",
    "            'profile_index', 'profile_direction']\n",
    "oxy_vars = vars_all + [\"oxygen_concentration\"]\n",
    "eng_vars = vars_all + [\"m_depth\", \"heading\", \"pitch\", \"roll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_sci = ts_sci[sci_vars]\n",
    "ts_oxy = ts_oxy[oxy_vars]\n",
    "ts_eng = ts_eng[eng_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = xr.merge([ts_sci, ts_oxy, ts_eng], compat = \"no_conflicts\", \n",
    "              join  = \"outer\", combine_attrs = \"override\")\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any(np.isnan(ts.latitude.values))\n",
    "# good = ~np.isnan(ts.latitude.values + ts.longitude.values)\n",
    "\n",
    "# print(np.nanmax(ts.latitude.values))\n",
    "# print(np.max(ts.latitude.values[good]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculate attributes as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = ~np.isnan(ts.latitude.values + ts.longitude.values)\n",
    "ts.attrs['geospatial_lat_max'] = np.nanmax(ts.latitude.values[good])\n",
    "ts.attrs['geospatial_lat_min'] = np.nanmin(ts.latitude.values[good])\n",
    "ts.attrs['geospatial_lon_max'] = np.nanmax(ts.longitude.values[good])\n",
    "ts.attrs['geospatial_lon_min'] = np.nanmin(ts.longitude.values[good])\n",
    "ts.attrs['geospatial_lat_units'] = 'degrees_north'\n",
    "ts.attrs['geospatial_lon_units'] = 'degrees_east'\n",
    "\n",
    "dt = ts.time.values\n",
    "ts.attrs['time_coverage_start'] = '%s' % dt[0]\n",
    "ts.attrs['time_coverage_end'] = '%s' % dt[-1]\n",
    "\n",
    "ts.attrs['deployment_start'] = str(dt[0].astype('datetime64[s]'))\n",
    "ts.attrs['deployment_end'] = str(dt[-1].astype('datetime64[s]'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculate profile values as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_good = np.where(~np.isnan(ts.m_depth))[0]\n",
    "ts.m_depth.values = np.interp(np.arange(len(ts.m_depth)), good, ts.m_depth.values[good])\n",
    "ts = get_profiles_esd(ts, \"m_depth\")\n",
    "\n",
    "# tg_ind = utils.find_gaps(ts.time.values[depth_good], ts.time.values, 300)\n",
    "# np.where(tg_ind)\n",
    "# dep = ts.m_depth.to_pandas()\n",
    "\n",
    "ts = utils.get_distance_over_ground(ts)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outname = os.path.join(l1tsdir, f\"{deployment}-union.nc\")\n",
    "ts.to_netcdf(outname, 'w',\n",
    "             encoding={'time': {'units': 'seconds since 1970-01-01T00:00:00Z',\n",
    "                                '_FillValue': np.nan,\n",
    "                                'dtype': 'float64'}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esdgliderutils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
